{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157728b-a49a-4994-b236-55b452b6f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 3: Set up paths and parameters\n",
    "# Update these paths according to your directory structure\n",
    "dataset_path = \"/kaggle/input/dogs-vs-cats\"  # Change this to your dataset path\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "test_dir = os.path.join(dataset_path, \"test1\")\n",
    "\n",
    "# If you're using local files, uncomment and modify these lines:\n",
    "# train_dir = \"data/train\"\n",
    "# test_dir = \"data/test1\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "# Step 4: Data Preparation and Preprocessing\n",
    "# Create data generators with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Using 20% for validation\n",
    ")\n",
    "\n",
    "# Data generator for validation (only rescaling)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Data generator for test (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Step 5: Explore the data\n",
    "print(\"Class indices:\", train_generator.class_indices)\n",
    "print(\"Training samples:\", train_generator.samples)\n",
    "print(\"Validation samples:\", validation_generator.samples)\n",
    "\n",
    "# Visualize some sample images\n",
    "def plot_sample_images(generator, num_samples=8):\n",
    "    \"\"\"\n",
    "    Plot sample images from the generator\n",
    "    \"\"\"\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    # Get a batch of images\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Class: {class_names[int(labels[i])]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot sample images\n",
    "plot_sample_images(train_generator)\n",
    "\n",
    "# Step 6: Build the CNN Model\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Step 7: Define Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 8: Train the Model\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 9: Evaluate the Model\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Step 10: Model Evaluation\n",
    "# Evaluate on validation data\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Step 11: Make Predictions and Generate Classification Report\n",
    "# Get predictions\n",
    "validation_generator.reset()\n",
    "predictions = model.predict(validation_generator)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = validation_generator.classes\n",
    "\n",
    "# Classification report\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Save the Model\n",
    "model.save('dogs_vs_cats_cnn_model.h5')\n",
    "print(\"Model saved as 'dogs_vs_cats_cnn_model.h5'\")\n",
    "\n",
    "# Step 13: Test the Model on New Images (Optional)\n",
    "def predict_single_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Predict class for a single image\n",
    "    \"\"\"\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "    )\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    class_name = 'Dog' if prediction > 0.5 else 'Cat'\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Prediction: {class_name} (Confidence: {confidence:.2f})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return class_name, confidence\n",
    "\n",
    "# Example usage for single image prediction\n",
    "# Uncomment and modify the path to test on your own images\n",
    "# test_image_path = \"path_to_your_test_image.jpg\"\n",
    "# class_name, confidence = predict_single_image(model, test_image_path)\n",
    "# print(f\"Predicted: {class_name} with {confidence:.2f} confidence\")\n",
    "\n",
    "# Step 14: Improved Model (Optional - More Advanced Architecture)\n",
    "def create_improved_cnn_model():\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fifth Convolutional Block\n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training completed successfully!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
